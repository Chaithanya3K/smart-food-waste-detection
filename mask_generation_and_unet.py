# -*- coding: utf-8 -*-
"""Mask_Generation_And_UNET.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/158ZxvSxumuNN-vwYTbXbnNqgboD4zgw9
"""

import os
import json
import cv2
import numpy as np

# === Paths ===
image_dir = '/content/drive/MyDrive/Mask_traing'         # folder with original images
json_dir  = '/content/drive/MyDrive/mask_annotation'    # folder with VIA JSON files
mask_dir  = '/content/drive/MyDrive/mask_directory'         # save generated masks
os.makedirs(mask_dir, exist_ok=True)

json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]

for json_file in json_files:
    json_path = os.path.join(json_dir, json_file)
    with open(json_path, 'r') as f:
        data = json.load(f)

    # ðŸ”‘ Pick the right dictionary
    if "_via_img_metadata" in data:
        data = data["_via_img_metadata"]

    for key, ann in data.items():
        filename = ann.get("filename")
        regions = ann.get("regions", [])

        if not filename or not regions:
            continue

        image_path = os.path.join(image_dir, filename)
        if not os.path.exists(image_path):
            print(f"âš ï¸ Image not found, skipping: {filename}")
            continue

        img = cv2.imread(image_path)
        height, width = img.shape[:2]
        mask = np.zeros((height, width), dtype=np.uint8)

        for region in regions:
            shape_attr = region["shape_attributes"]
            if shape_attr["name"] == "polygon":
                all_x = shape_attr["all_points_x"]
                all_y = shape_attr["all_points_y"]
                points = np.array(list(zip(all_x, all_y)), dtype=np.int32)
                cv2.fillPoly(mask, [points], 255)

        mask_filename = os.path.splitext(filename)[0] + "_mask.png"
        mask_path = os.path.join(mask_dir, mask_filename)
        cv2.imwrite(mask_path, mask)
        print(f"âœ… Saved mask: {mask_filename}")

import os
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split

# === Paths ===
image_dir = '/content/drive/MyDrive/Mask_traing'         # folder with original images
  # folder with VIA JSON files
mask_dir  = '/content/drive/MyDrive/mask_directory'
IMG_SIZE = 256

# --- Load all images + masks ---
images, masks = [], []
for file in os.listdir(image_dir):
    if file.endswith(".jpg") or file.endswith(".png"):
        img_path = os.path.join(image_dir, file)
        mask_filename = os.path.splitext(file)[0] + "_mask.png"
        mask_path = os.path.join(mask_dir, mask_filename)

        if not os.path.exists(mask_path):
            print(f"âš ï¸ No mask found for {file}, skipping...")
            continue

        # Load + resize
        img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))
        img = img_to_array(img) / 255.0

        mask = load_img(mask_path, target_size=(IMG_SIZE, IMG_SIZE), color_mode="grayscale")
        mask = img_to_array(mask) / 255.0
        mask = (mask > 0.5).astype(np.float32)

        images.append(img)
        masks.append(mask)

X = np.array(images)
y = np.array(masks)

print("âœ… Dataset loaded:", X.shape, y.shape)

# --- Split into train/val ---
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

import os

image_dir = '/content/drive/MyDrive/Mask_traing'
mask_dir  = '/content/drive/MyDrive/mask_directory'

def check_mask(image_name):
    mask_name = os.path.splitext(image_name)[0] + "_mask.png"
    mask_path = os.path.join(mask_dir, mask_name)

    if os.path.exists(mask_path):
        print(f"âœ… Mask exists for {image_name} â†’ {mask_name}")
    else:
        print(f"âŒ Mask NOT found for {image_name}")

# ðŸ” check any two images
check_mask("10e.jpeg")
check_mask("11e.jpeg")

import cv2
import matplotlib.pyplot as plt

def show_image_and_mask(image_name):
    img_path = os.path.join(image_dir, image_name)
    mask_name = os.path.splitext(image_name)[0] + "_mask.png"
    mask_path = os.path.join(mask_dir, mask_name)

    if not os.path.exists(mask_path):
        print(f"âŒ No mask for {image_name}")
        return

    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    plt.figure(figsize=(8,4))
    plt.subplot(1,2,1)
    plt.title("Image")
    plt.imshow(img)
    plt.axis("off")

    plt.subplot(1,2,2)
    plt.title("Mask")
    plt.imshow(mask, cmap="gray")
    plt.axis("off")

    plt.show()

# ðŸ‘€ check two images visually
show_image_and_mask("10e.jpeg")
show_image_and_mask("11e.jpeg")

import matplotlib.pyplot as plt
import random

def visualize_samples(X, y, num_samples=3):
    if len(X) == 0 or len(y) == 0:
        print("âš ï¸ No data loaded! Check file paths and masks.")
        return

    idxs = random.sample(range(len(X)), min(num_samples, len(X)))

    for i in idxs:
        img = X[i]
        mask = y[i].squeeze()

        plt.figure(figsize=(12,4))

        # Original image
        plt.subplot(1,3,1)
        plt.imshow(img)
        plt.title("Image")
        plt.axis("off")

        # Mask
        plt.subplot(1,3,2)
        plt.imshow(mask, cmap="gray")
        plt.title("Mask")
        plt.axis("off")

        # Overlay
        plt.subplot(1,3,3)
        plt.imshow(img)
        plt.imshow(mask, cmap="jet", alpha=0.4)
        plt.title("Overlay")
        plt.axis("off")

        plt.show()

# ðŸ‘‡ Run immediately after loading your dataset
visualize_samples(X_train, y_train, num_samples=5)

def unet_model(input_size=(IMG_SIZE, IMG_SIZE, 3)):
    inputs = layers.Input(input_size)

    # Encoder
    c1 = layers.Conv2D(64, 3, activation="relu", padding="same")(inputs)
    c1 = layers.Conv2D(64, 3, activation="relu", padding="same")(c1)
    p1 = layers.MaxPooling2D()(c1)

    c2 = layers.Conv2D(128, 3, activation="relu", padding="same")(p1)
    c2 = layers.Conv2D(128, 3, activation="relu", padding="same")(c2)
    p2 = layers.MaxPooling2D()(c2)

    c3 = layers.Conv2D(256, 3, activation="relu", padding="same")(p2)
    c3 = layers.Conv2D(256, 3, activation="relu", padding="same")(c3)
    p3 = layers.MaxPooling2D()(c3)

    c4 = layers.Conv2D(512, 3, activation="relu", padding="same")(p3)
    c4 = layers.Conv2D(512, 3, activation="relu", padding="same")(c4)
    p4 = layers.MaxPooling2D()(c4)

    # Bottleneck
    c5 = layers.Conv2D(1024, 3, activation="relu", padding="same")(p4)
    c5 = layers.Conv2D(1024, 3, activation="relu", padding="same")(c5)

    # Decoder
    u6 = layers.Conv2DTranspose(512, 2, strides=2, padding="same")(c5)
    u6 = layers.concatenate([u6, c4])
    c6 = layers.Conv2D(512, 3, activation="relu", padding="same")(u6)
    c6 = layers.Conv2D(512, 3, activation="relu", padding="same")(c6)

    u7 = layers.Conv2DTranspose(256, 2, strides=2, padding="same")(c6)
    u7 = layers.concatenate([u7, c3])
    c7 = layers.Conv2D(256, 3, activation="relu", padding="same")(u7)
    c7 = layers.Conv2D(256, 3, activation="relu", padding="same")(c7)

    u8 = layers.Conv2DTranspose(128, 2, strides=2, padding="same")(c7)
    u8 = layers.concatenate([u8, c2])
    c8 = layers.Conv2D(128, 3, activation="relu", padding="same")(u8)
    c8 = layers.Conv2D(128, 3, activation="relu", padding="same")(c8)

    u9 = layers.Conv2DTranspose(64, 2, strides=2, padding="same")(c8)
    u9 = layers.concatenate([u9, c1])
    c9 = layers.Conv2D(64, 3, activation="relu", padding="same")(u9)
    c9 = layers.Conv2D(64, 3, activation="relu", padding="same")(c9)

    outputs = layers.Conv2D(1, 1, activation="sigmoid")(c9)

    return models.Model(inputs=[inputs], outputs=[outputs])

model = unet_model()
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    batch_size=8,
    epochs=500
)

# # Save model
# model.save("/content/unet_food_segmentation.h5")
# print("âœ… U-Net Model Saved!")

from sklearn.metrics import jaccard_score
import numpy as np

# --- Custom Metrics ---
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = (y_pred.flatten() > 0.5).astype(np.float32)
    intersection = np.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def iou_score(y_true, y_pred, smooth=1e-6):
    y_true_f = y_true.flatten()
    y_pred_f = (y_pred.flatten() > 0.5).astype(np.float32)
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)

# --- Evaluate on Validation Set ---
preds = model.predict(X_val)
preds = (preds > 0.5).astype(np.float32)

dice_scores, iou_scores = [], []

for i in range(len(X_val)):
    dice_scores.append(dice_coef(y_val[i], preds[i]))
    iou_scores.append(iou_score(y_val[i], preds[i]))

print("âœ… Validation Loss:", history.history['val_loss'][-1])
print("âœ… Validation Accuracy:", history.history['val_accuracy'][-1])
print("âœ… Dice Coefficient:", np.mean(dice_scores))
print("âœ… IoU Score:", np.mean(iou_scores))

# After training
# âœ… Save model in Google Drive safely
model_save_path = "/content/drive/MyDrive/unet_food_2_segmentation.h5"
model.save(model_save_path)

print(f"âœ… U-Net Model Saved at {model_save_path}")

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# === Load Trained U-Net Model ===
model_path = "/content/drive/MyDrive/unet_food_segmentation.h5"  # or .keras
model = tf.keras.models.load_model(model_path, compile=False)
print("âœ… Model loaded!")

IMG_SIZE = 256  # must match training

# === Pick one image (before or after) ===
img_path = "/content/drive/MyDrive/food before meal/image101.jpg"

# Load + preprocess
img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))
img_array = img_to_array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

# Predict mask
pred_mask = model.predict(img_array)[0]

# Threshold â†’ binary mask
binary_mask = (pred_mask > 0.5).astype(np.uint8).squeeze()

# === Show results ===
plt.figure(figsize=(12,6))

plt.subplot(1,3,1)
plt.imshow(img)
plt.title("Original Image")
plt.axis("off")

plt.subplot(1,3,2)
plt.imshow(binary_mask, cmap="gray")
plt.title("Predicted Mask")
plt.axis("off")

plt.subplot(1,3,3)
plt.imshow(img)
plt.imshow(binary_mask, cmap="jet", alpha=0.4)  # Overlay
plt.title("Overlay")
plt.axis("off")

plt.show()

import tensorflow as tf
from tensorflow.keras.models import load_model

model_path = "/content/drive/MyDrive/unet_food_2_segmentation.h5"
model = load_model(model_path)
print("âœ… Model loaded")

import os
import cv2
import numpy as np

IMG_SIZE = 256  # change if different

def load_test_data(image_dir, mask_dir):
    images = []
    masks = []

    image_files = sorted(os.listdir(image_dir))
    mask_files = sorted(os.listdir(mask_dir))

    for img, msk in zip(image_files, mask_files):
        img_path = os.path.join(image_dir, img)
        msk_path = os.path.join(mask_dir, msk)

        image = cv2.imread(img_path)
        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
        image = image / 255.0

        mask = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, (IMG_SIZE, IMG_SIZE))
        mask = mask / 255.0
        mask = np.expand_dims(mask, axis=-1)

        images.append(image)
        masks.append(mask)

    return np.array(images), np.array(masks)

X_test, y_test = load_test_data(
    "/content/test/images",
    "/content/test/masks"
)

print("Test images:", X_test.shape)
print("Test masks:", y_test.shape)

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(np.uint8)

def pixel_accuracy(y_true, y_pred):
    correct = np.sum(y_true == y_pred)
    total = y_true.size
    return correct / total

acc = pixel_accuracy(y_test, y_pred)
print(f"âœ… Pixel Accuracy: {acc:.4f}")

def dice_coefficient(y_true, y_pred, smooth=1):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

dice = dice_coefficient(y_test, y_pred)
print(f"âœ… Dice Coefficient: {dice:.4f}")

def iou_score(y_true, y_pred, smooth=1):
    y_true_f = y_true.flatten()
    y_pred_f = y_pred.flatten()
    intersection = np.sum(y_true_f * y_pred_f)
    union = np.sum(y_true_f) + np.sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)

iou = iou_score(y_test, y_pred)
print(f"âœ… IoU Score: {iou:.4f}")